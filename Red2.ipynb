{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-17T18:51:36.028921Z",
     "start_time": "2025-11-17T18:51:04.495641Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet34_Weights\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from PIL import Image\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from sklearn.model_selection import KFold"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "DATASET_PATH = config[\"DATASET_PATH\"]"
   ],
   "id": "f169ebcecfe3118b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ChestXrayDataset3Clases(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        labels_map = {\"NORMAL\": 0, \"BACTERIA\": 1, \"VIRUS\": 2}\n",
    "        for folder, label in labels_map.items():\n",
    "            folder_path = os.path.join(root_dir, \"PNEUMONIA\") if folder != \"NORMAL\" else os.path.join(root_dir, \"NORMAL\")\n",
    "            if folder != \"NORMAL\":\n",
    "                folder_path = os.path.join(folder_path, folder)\n",
    "            if not os.path.exists(folder_path):\n",
    "                continue\n",
    "            for root, _, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
    "                        self.samples.append((os.path.join(root, file), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ],
   "id": "608f517016a786c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1,0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std =[0.229, 0.224, 0.225])\n",
    "])"
   ],
   "id": "7d028a320d13006f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TransformedSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ],
   "id": "90fb6028853fdb1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_data = ChestXrayDataset3Clases(os.path.join(DATASET_PATH, \"train\"), transform=None)\n",
    "val_data = ChestXrayDataset3Clases(os.path.join(DATASET_PATH, \"val\"), transform=None)\n",
    "full_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "\n",
    "test_data  = ChestXrayDataset3Clases(os.path.join(DATASET_PATH, \"test\"), val_transform)\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)"
   ],
   "id": "3bf2f417ec077a7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"cuda\")\n",
    "else:\n",
    "    try:\n",
    "        import torch_directml\n",
    "        device = torch_directml.device()\n",
    "        print(\"amd\")\n",
    "    except ImportError:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"cpu\")\n"
   ],
   "id": "6bff504b715d8fca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResNet34FineTune(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ResNet34FineTune, self).__init__()\n",
    "        self.resnet = models.resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.45),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.35),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        return self.fc(features)\n"
   ],
   "id": "cd8e37b23140d192"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "\n",
    "all_train_losses, all_val_losses = [], []\n",
    "all_train_accs, all_val_accs = [], []"
   ],
   "id": "edc69843cd99db68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for fold, (train_idx, val_idx) in enumerate(kf.split(full_data)):\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"chest_xray_resnet34\",\n",
    "        name=f\"Fold_{fold + 1}\",\n",
    "        config={\n",
    "            \"epochs\": 35,\n",
    "            \"batch_size\": 64,\n",
    "            \"learning_rate_fc\": 1e-4,\n",
    "            \"learning_rate_resnet\": 8e-6,\n",
    "            \"weight_decay\": 0.0016,\n",
    "            \"architecture\": \"ResNet34\",\n",
    "            \"k_folds\": 5\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--Fold {fold+1}--\")\n",
    "\n",
    "    train_subset = Subset(full_data, train_idx)\n",
    "    val_subset   = Subset(full_data, val_idx)\n",
    "\n",
    "    train_subset = TransformedSubset(train_subset, transform=train_transform)\n",
    "    val_subset = TransformedSubset(val_subset, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "    val_loader   = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = ResNet34FineTune(num_classes=3).to(device)\n",
    "    for name, param in model.resnet.named_parameters():\n",
    "        if \"layer2\" in name or \"layer3\" in name or \"layer4\" in name:\n",
    "            param.requires_grad = True\n",
    "\n",
    "    labels = [full_data[i][1] for i in train_idx]\n",
    "    counts = Counter(labels)\n",
    "    total = sum(counts.values())\n",
    "    weights = torch.tensor(\n",
    "        [total / (3 * counts[i]) if counts[i] > 0 else 0 for i in range(3)],\n",
    "        dtype=torch.float\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.016)\n",
    "    optimizer = optim.Adam([\n",
    "        {\"params\": model.resnet.layer2.parameters(), \"lr\": 8e-6},\n",
    "        {\"params\": model.resnet.layer3.parameters(), \"lr\": 2e-5},\n",
    "        {\"params\": model.resnet.layer4.parameters(), \"lr\": 2e-5},\n",
    "        {\"params\": model.fc.parameters(), \"lr\": 1e-4}\n",
    "    ], weight_decay=0.0016)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=6,\n",
    "        threshold=0.002,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_loss = 10\n",
    "    patience_counter_loss = 0\n",
    "\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\n",
    "    for epoch in range(35):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}: Train Loss {train_loss:.4f} Train Acc {train_acc:.2f}% \"\n",
    "              f\"Val Loss {val_loss:.4f} Val Acc {val_acc:.2f}%\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        all_train_losses.append(train_loss)\n",
    "        all_val_losses.append(val_loss)\n",
    "        all_train_accs.append(train_acc)\n",
    "        all_val_accs.append(val_acc)\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"fold\": fold + 1,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "\n",
    "        if val_loss < best_val_loss - 1e-3:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter_loss = 0\n",
    "            torch.save(model.state_dict(), f\"best_resnet34_fold{fold + 1}.pth\")\n",
    "        else:\n",
    "            patience_counter_loss += 1\n",
    "            if patience_counter_loss >= patience_loss:\n",
    "                print(\"Early stopping activado (criterio: val_loss)\")\n",
    "                break\n",
    "\n",
    "    results[fold] = best_val_loss\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Train Loss\", marker='o')\n",
    "    plt.plot(val_losses, label=\"Val Loss\", marker='o')\n",
    "    plt.title(f\"Loss por época (Fold {fold+1})\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label=\"Train Acc\", marker='o')\n",
    "    plt.plot(val_accs, label=\"Val Acc\", marker='o')\n",
    "    plt.title(f\"Accuracy por época (Fold {fold+1})\")\n",
    "    plt.xlabel(\"Época\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    model.eval()\n",
    "    classes = [\"NORMAL\", \"BACTERIA\", \"VIRUS\"]\n",
    "    all_labels, all_preds = [], []\n",
    "    class_correct = defaultdict(int)\n",
    "    class_total = defaultdict(int)\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            for label, pred in zip(labels, predicted):\n",
    "                class_total[classes[label]] += 1\n",
    "                if label == pred:\n",
    "                    class_correct[classes[label]] += 1\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"\\nFold {fold+1} - Accuracy en test: {accuracy:.2f}%\")\n",
    "    print(\"Accuracy por clase:\")\n",
    "    for c in classes:\n",
    "        acc = 100 * class_correct[c] / class_total[c] if class_total[c] > 0 else 0\n",
    "        print(f\"{c}: {acc:.2f}%\")\n",
    "\n",
    "    wandb.log({f\"test_accuracy_fold{fold+1}\": accuracy})\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(f\"Matriz de Confusión (Fold {fold+1})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "id": "e2969ce2ef358113"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\nResultados por fold:\")\n",
    "for fold, acc in results.items():\n",
    "    print(f\"Fold {fold + 1}: {acc:.4f}\")"
   ],
   "id": "3b589f34f4e7a6b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mean_val_loss = sum(results.values()) / len(results)\n",
    "print(f\"\\nMedia de validación (loss): {mean_val_loss:.4f}\")\n",
    "wandb.log({\"mean_val_loss\": mean_val_loss})\n"
   ],
   "id": "3033781eb12a5a90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_train_losses, label=\"Train Loss\", marker='o')\n",
    "plt.plot(all_val_losses, label=\"Val Loss\", marker='o')\n",
    "plt.title(\"Loss acumulado (todos los folds)\")\n",
    "plt.xlabel(\"Época total\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ],
   "id": "c02b81ce5b09b65a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_train_accs, label=\"Train Acc\", marker='o')\n",
    "plt.plot(all_val_accs, label=\"Val Acc\", marker='o')\n",
    "plt.title(\"Accuracy acumulado (todos los folds)\")\n",
    "plt.xlabel(\"Época total\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()"
   ],
   "id": "a02b35f336f506b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d10c79981c3f41a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
